"""
Spark Structured Streaming job - Äá»c tá»« Kafka, dá»± Ä‘oÃ¡n vÃ  gá»­i láº¡i káº¿t quáº£
"""
from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, to_json, struct
from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType
from pyspark.ml import PipelineModel
import time

def streaming_prediction():
    # Khá»Ÿi táº¡o Spark Session
    spark = SparkSession.builder \
        .appName("HousePriceStreamingPrediction") \
        .config("spark.driver.memory", "4g") \
        .config("spark.executor.memory", "4g") \
        .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.0") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    
    print("=" * 60)
    print("SPARK STREAMING - Dá»° ÄOÃN GIÃ NHÃ€")
    print("=" * 60)
    
    # Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    model_path = "models/house_price_model"
    print(f"ğŸ“‚ Äang táº£i mÃ´ hÃ¬nh tá»«: {model_path}")
    model = PipelineModel.load(model_path)
    print("âœ“ ÄÃ£ táº£i mÃ´ hÃ¬nh thÃ nh cÃ´ng")
    
    # Schema cho dá»¯ liá»‡u tá»« Kafka
    schema = StructType([
        StructField("id", IntegerType(), True),
        StructField("MedInc", DoubleType(), True),
        StructField("HouseAge", DoubleType(), True),
        StructField("AveRooms", DoubleType(), True),
        StructField("AveBedrms", DoubleType(), True),
        StructField("Population", DoubleType(), True),
        StructField("AveOccup", DoubleType(), True),
        StructField("Latitude", DoubleType(), True),
        StructField("Longitude", DoubleType(), True),
        StructField("actual_price", DoubleType(), True)
    ])
    
    # Äá»c dá»¯ liá»‡u tá»« Kafka
    print("ğŸ“¥ Äang káº¿t ná»‘i Ä‘áº¿n Kafka topic: house-prices-input")
    df_stream = spark \
        .readStream \
        .format("kafka") \
        .option("kafka.bootstrap.servers", "localhost:9092") \
        .option("subscribe", "house-prices-input") \
        .option("startingOffsets", "latest") \
        .load()
    
    # Parse JSON
    df_parsed = df_stream.select(
        from_json(col("value").cast("string"), schema).alias("data")
    ).select("data.*")
    
    # Dá»± Ä‘oÃ¡n
    predictions = model.transform(df_parsed)
    
    # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ gá»­i láº¡i Kafka
    result = predictions.select(
        col("id"),
        col("actual_price"),
        col("prediction").alias("predicted_price"),
        (col("prediction") - col("actual_price")).alias("error"),
        ((col("prediction") - col("actual_price")) / col("actual_price") * 100).alias("error_percentage")
    )
    
    # Chuyá»ƒn thÃ nh JSON Ä‘á»ƒ gá»­i vÃ o Kafka
    kafka_output = result.select(
        to_json(struct("*")).alias("value")
    )
    
    # Ghi káº¿t quáº£ vÃ o Kafka topic má»›i
    query = kafka_output \
        .writeStream \
        .format("kafka") \
        .option("kafka.bootstrap.servers", "localhost:9092") \
        .option("topic", "house-prices-output") \
        .option("checkpointLocation", "/tmp/checkpoint") \
        .start()
    
    # Console output Ä‘á»ƒ debug
    console_query = result \
        .writeStream \
        .outputMode("append") \
        .format("console") \
        .option("truncate", False) \
        .start()
    
    print("=" * 60)
    print("âœ“ Streaming Ä‘Ã£ báº¯t Ä‘áº§u!")
    print("ğŸ“Š Äang xá»­ lÃ½ dá»¯ liá»‡u vÃ  gá»­i káº¿t quáº£ vÃ o: house-prices-output")
    print("=" * 60)
    
    # Chá» cho Ä‘áº¿n khi bá»‹ dá»«ng
    try:
        query.awaitTermination()
        console_query.awaitTermination()
    except KeyboardInterrupt:
        print("\nâš ï¸  Äang dá»«ng streaming...")
        query.stop()
        console_query.stop()
        spark.stop()
        print("âœ“ ÄÃ£ dá»«ng streaming")

if __name__ == "__main__":
    streaming_prediction()