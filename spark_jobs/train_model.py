"""
Spark ML job Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest
"""
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml import Pipeline
import os

def train_model():
    # Khá»Ÿi táº¡o Spark Session
    spark = SparkSession.builder \
        .appName("HousePriceModelTraining") \
        .config("spark.hadoop.fs.defaultFS", "file:///") \
        .config("spark.local.dir", "/tmp/spark_local") \
        .config("spark.driver.memory", "4g") \
        .config("spark.executor.memory", "4g") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    
    print("=" * 60)
    print("Báº®T Äáº¦U HUáº¤N LUYá»†N MÃ” HÃŒNH")
    print("=" * 60)
    
    # Äá»c dá»¯ liá»‡u huáº¥n luyá»‡n
    data_path = os.path.abspath("data/train_data.csv")
    df = spark.read.csv(f"file://{data_path}", header=True, inferSchema=True)
    
    print(f"\nâœ“ ÄÃ£ Ä‘á»c {df.count()} máº«u tá»« {data_path}")
    print("\nSchema:")
    df.printSchema()
    
    # CÃ¡c cá»™t Ä‘áº·c trÆ°ng (táº¥t cáº£ trá»« cá»™t target)
    feature_cols = [col for col in df.columns if col != 'target']
    
    # Táº¡o vector assembler
    assembler = VectorAssembler(
        inputCols=feature_cols,
        outputCol="features"
    )
    
    # Táº¡o mÃ´ hÃ¬nh Random Forest
    rf = RandomForestRegressor(
        featuresCol="features",
        labelCol="target",
        numTrees=100,
        maxDepth=10,
        seed=42
    )
    
    # Táº¡o pipeline
    pipeline = Pipeline(stages=[assembler, rf])
    
    # Chia dá»¯ liá»‡u train/test
    train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)
    
    print(f"\nâœ“ Dá»¯ liá»‡u train: {train_data.count()} máº«u")
    print(f"âœ“ Dá»¯ liá»‡u test: {test_data.count()} máº«u")
    
    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    print("\nğŸ”„ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest...")
    model = pipeline.fit(train_data)
    
    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
    predictions = model.transform(test_data)
    
    evaluator_rmse = RegressionEvaluator(
        labelCol="target",
        predictionCol="prediction",
        metricName="rmse"
    )
    
    evaluator_r2 = RegressionEvaluator(
        labelCol="target",
        predictionCol="prediction",
        metricName="r2"
    )
    
    evaluator_mae = RegressionEvaluator(
        labelCol="target",
        predictionCol="prediction",
        metricName="mae"
    )
    
    rmse = evaluator_rmse.evaluate(predictions)
    r2 = evaluator_r2.evaluate(predictions)
    mae = evaluator_mae.evaluate(predictions)
    
    print("\n" + "=" * 60)
    print("Káº¾T QUáº¢ ÄÃNH GIÃ MÃ” HÃŒNH")
    print("=" * 60)
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE:  {mae:.4f}")
    print(f"RÂ²:   {r2:.4f}")
    print("=" * 60)
    
    # LÆ°u mÃ´ hÃ¬nh
    model_path = "models/house_price_model"
    os.makedirs("models", exist_ok=True)
    model.write().overwrite().save(model_path)
    
    print(f"\nâœ“ ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o: {model_path}")
    
    # Hiá»ƒn thá»‹ má»™t sá»‘ dá»± Ä‘oÃ¡n máº«u
    print("\nMá»™t sá»‘ dá»± Ä‘oÃ¡n máº«u:")
    predictions.select("target", "prediction").show(10, truncate=False)
    
    spark.stop()
    print("\nâœ“ HoÃ n thÃ nh quÃ¡ trÃ¬nh huáº¥n luyá»‡n!")

if __name__ == "__main__":
    train_model()