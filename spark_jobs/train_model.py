"""
Spark ML job Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest
Äá»c dá»¯ liá»‡u tá»« HDFS vÃ  lÆ°u model lÃªn HDFS
"""
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml import Pipeline
import os
import sys

# Cáº¥u hÃ¬nh HDFS
HDFS_NAMENODE = os.getenv("HDFS_NAMENODE", "hdfs://192.168.80.148:9000")
HDFS_DATA_DIR = os.getenv("HDFS_DATA_DIR", "/bigdata/house_prices")
HDFS_MODEL_DIR = os.getenv("HDFS_MODEL_DIR", "/bigdata/house_prices/models")

def train_model():
    # Khá»Ÿi táº¡o Spark Session vá»›i HDFS
    spark = SparkSession.builder \
        .appName("HousePriceModelTraining") \
        .config("spark.hadoop.fs.defaultFS", HDFS_NAMENODE) \
        .config("spark.local.dir", "/tmp/spark_local") \
        .config("spark.driver.memory", "4g") \
        .config("spark.executor.memory", "4g") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    
    print("=" * 60)
    print("Báº®T Äáº¦U HUáº¤N LUYá»†N MÃ” HÃŒNH")
    print("=" * 60)
    print(f"HDFS Namenode: {HDFS_NAMENODE}")
    print(f"HDFS Data Dir: {HDFS_DATA_DIR}")
    print(f"HDFS Model Dir: {HDFS_MODEL_DIR}")
    
    # Äá»c dá»¯ liá»‡u huáº¥n luyá»‡n tá»« HDFS
    hdfs_train_path = f"{HDFS_DATA_DIR}/train_data.csv"
    print(f"\nğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« HDFS: {hdfs_train_path}")
    
    try:
        df = spark.read.csv(hdfs_train_path, header=True, inferSchema=True)
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c dá»¯ liá»‡u tá»« HDFS: {e}")
        print(f"ğŸ’¡ Äáº£m báº£o Ä‘Ã£ upload dá»¯ liá»‡u lÃªn HDFS báº±ng script upload_to_hdfs.py")
        spark.stop()
        sys.exit(1)
    
    print(f"\nâœ“ ÄÃ£ Ä‘á»c {df.count()} máº«u tá»« {data_path}")
    print("\nSchema:")
    df.printSchema()
    
    # CÃ¡c cá»™t Ä‘áº·c trÆ°ng (táº¥t cáº£ trá»« cá»™t target)
    feature_cols = [col for col in df.columns if col != 'target']
    
    # Táº¡o vector assembler
    assembler = VectorAssembler(
        inputCols=feature_cols,
        outputCol="features"
    )
    
    # Táº¡o mÃ´ hÃ¬nh Random Forest
    rf = RandomForestRegressor(
        featuresCol="features",
        labelCol="target",
        numTrees=100,
        maxDepth=10,
        seed=42
    )
    
    # Táº¡o pipeline
    pipeline = Pipeline(stages=[assembler, rf])
    
    # Chia dá»¯ liá»‡u train/test
    train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)
    
    print(f"\nâœ“ Dá»¯ liá»‡u train: {train_data.count()} máº«u")
    print(f"âœ“ Dá»¯ liá»‡u test: {test_data.count()} máº«u")
    
    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    print("\nğŸ”„ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest...")
    model = pipeline.fit(train_data)
    
    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
    predictions = model.transform(test_data)
    
    evaluator_rmse = RegressionEvaluator(
        labelCol="target",
        predictionCol="prediction",
        metricName="rmse"
    )
    
    evaluator_r2 = RegressionEvaluator(
        labelCol="target",
        predictionCol="prediction",
        metricName="r2"
    )
    
    evaluator_mae = RegressionEvaluator(
        labelCol="target",
        predictionCol="prediction",
        metricName="mae"
    )
    
    rmse = evaluator_rmse.evaluate(predictions)
    r2 = evaluator_r2.evaluate(predictions)
    mae = evaluator_mae.evaluate(predictions)
    
    print("\n" + "=" * 60)
    print("Káº¾T QUáº¢ ÄÃNH GIÃ MÃ” HÃŒNH")
    print("=" * 60)
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE:  {mae:.4f}")
    print(f"RÂ²:   {r2:.4f}")
    print("=" * 60)
    
    # LÆ°u mÃ´ hÃ¬nh lÃªn HDFS
    hdfs_model_path = f"{HDFS_MODEL_DIR}/house_price_model"
    print(f"\nğŸ’¾ Äang lÆ°u mÃ´ hÃ¬nh lÃªn HDFS: {hdfs_model_path}")
    
    try:
        model.write().overwrite().save(hdfs_model_path)
        print(f"âœ“ ÄÃ£ lÆ°u mÃ´ hÃ¬nh vÃ o HDFS: {hdfs_model_path}")
    except Exception as e:
        print(f"âŒ Lá»—i khi lÆ°u mÃ´ hÃ¬nh lÃªn HDFS: {e}")
        # Fallback: lÆ°u local náº¿u HDFS lá»—i
        local_model_path = "models/house_price_model"
        os.makedirs("models", exist_ok=True)
        model.write().overwrite().save(local_model_path)
        print(f"âš ï¸  ÄÃ£ lÆ°u mÃ´ hÃ¬nh local (fallback): {local_model_path}")
    
    # Hiá»ƒn thá»‹ má»™t sá»‘ dá»± Ä‘oÃ¡n máº«u
    print("\nMá»™t sá»‘ dá»± Ä‘oÃ¡n máº«u:")
    predictions.select("target", "prediction").show(10, truncate=False)
    
    spark.stop()
    print("\nâœ“ HoÃ n thÃ nh quÃ¡ trÃ¬nh huáº¥n luyá»‡n!")

if __name__ == "__main__":
    train_model()