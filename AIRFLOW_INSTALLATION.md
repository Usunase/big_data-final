# HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  khá»Ÿi Ä‘á»™ng Airflow tá»« Ä‘áº§u

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- **Airflow Version**: 3.1.3 (hoáº·c má»›i hÆ¡n)
- Python 3.9+ (khuyáº¿n nghá»‹ Python 3.10 hoáº·c 3.11)
- pip (Python package manager)
- Tá»‘i thiá»ƒu 4GB RAM
- Káº¿t ná»‘i Internet Ä‘á»ƒ táº£i packages

**LÆ°u Ã½:** Airflow 3.x cÃ³ má»™t sá»‘ thay Ä‘á»•i so vá»›i 2.x vá» cáº¥u trÃºc vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng.

---

## ğŸš€ BÆ°á»›c 1: Táº¡o Virtual Environment (Khuyáº¿n nghá»‹)

### Táº¡i sao cáº§n Virtual Environment?
- TÃ¡ch biá»‡t dependencies cá»§a Airflow vá»›i há»‡ thá»‘ng
- TrÃ¡nh xung Ä‘á»™t vá»›i cÃ¡c Python packages khÃ¡c
- Dá»… quáº£n lÃ½ vÃ  dá»n dáº¹p

### CÃ¡ch táº¡o:

```bash
# Táº¡o thÆ° má»¥c cho Airflow
mkdir -p ~/airflow
cd ~/airflow

# Táº¡o virtual environment
python3 -m venv venv

# KÃ­ch hoáº¡t virtual environment
source venv/bin/activate  # Linux/Mac
# hoáº·c
# venv\Scripts\activate  # Windows
```

**LÆ°u Ã½:** Má»—i láº§n lÃ m viá»‡c vá»›i Airflow, báº¡n cáº§n activate virtual environment:
```bash
cd ~/airflow
source venv/bin/activate
```

---

## ğŸ“¦ BÆ°á»›c 2: CÃ i Ä‘áº·t Airflow

### 2.1. CÃ i Ä‘áº·t Airflow Core

```bash
# Äáº£m báº£o Ä‘Ã£ activate venv
source ~/airflow/venv/bin/activate

# CÃ i Ä‘áº·t Airflow 3.1.3
pip install apache-airflow==3.1.3

# CÃ i Ä‘áº·t Spark provider (Ä‘á»ƒ submit Spark jobs)
# Kiá»ƒm tra version tÆ°Æ¡ng thÃ­ch vá»›i Airflow 3.1.3
pip install apache-airflow-providers-apache-spark
```

**LÆ°u Ã½ Airflow 3.x:**
- Airflow 3.x cÃ³ cáº¥u trÃºc khÃ¡c vá»›i 2.x
- Má»™t sá»‘ operators Ä‘Ã£ Ä‘Æ°á»£c di chuyá»ƒn sang `airflow.providers`
- Import paths cÃ³ thá»ƒ khÃ¡c má»™t chÃºt

### 2.2. CÃ i Ä‘áº·t cÃ¡c Python dependencies cáº§n thiáº¿t

```bash
# CÃ i Ä‘áº·t cÃ¡c packages cho ML pipeline
pip install pyspark==4.0.0
pip install pandas>=1.5.0
pip install scikit-learn>=1.0.0
pip install kafka-python>=2.0.0
pip install matplotlib>=3.5.0
pip install numpy>=1.21.0
```

**Hoáº·c cÃ i tá»« requirements.txt:**
```bash
cd /home/haminhchien/Documents/bigdata/final_project
pip install -r requirements.txt
```

---

## âš™ï¸ BÆ°á»›c 3: Khá»Ÿi táº¡o Airflow Database

### 3.1. Set AIRFLOW_HOME (tÃ¹y chá»n)

```bash
export AIRFLOW_HOME=~/airflow
```

Hoáº·c thÃªm vÃ o `~/.bashrc` hoáº·c `~/.zshrc`:
```bash
echo 'export AIRFLOW_HOME=~/airflow' >> ~/.bashrc
source ~/.bashrc
```

### 3.2. Khá»Ÿi táº¡o database

```bash
# Äáº£m báº£o Ä‘Ã£ activate venv
source ~/airflow/venv/bin/activate

# Khá»Ÿi táº¡o Airflow database
airflow db init
```

**Káº¿t quáº£:** Táº¡o cÃ¡c file vÃ  thÆ° má»¥c trong `~/airflow/`:
- `airflow.cfg` - File cáº¥u hÃ¬nh
- `airflow.db` - SQLite database
- `logs/` - ThÆ° má»¥c logs
- `dags/` - ThÆ° má»¥c chá»©a DAGs

---

## ğŸ‘¤ BÆ°á»›c 4: Táº¡o User Admin

```bash
# Äáº£m báº£o Ä‘Ã£ activate venv
source ~/airflow/venv/bin/activate

# Táº¡o user admin
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin
```

**ThÃ´ng tin Ä‘Äƒng nháº­p:**
- Username: `admin`
- Password: `admin`

---

## ğŸ”— BÆ°á»›c 5: Káº¿t ná»‘i DAGs tá»« Project

### 5.1. Táº¡o symlink tá»« project Ä‘áº¿n Airflow

```bash
# Táº¡o symlink Ä‘á»ƒ Airflow nháº­n DAGs tá»« project
ln -sf /home/haminhchien/Documents/bigdata/final_project/dags/ml_pipeline_dag.py \
    ~/airflow/dags/ml_pipeline_dag.py
```

### 5.2. Kiá»ƒm tra DAGs Ä‘Æ°á»£c nháº­n diá»‡n

```bash
source ~/airflow/venv/bin/activate
airflow dags list | grep ml_streaming
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
dag_id                    | fileloc      | owners  | is_paused
ml_streaming_pipeline     | ...          | airflow | True
ml_streaming_visualization| ...          | airflow | True
```

---

## ğŸ¯ BÆ°á»›c 6: Khá»Ÿi Ä‘á»™ng Airflow

### 6.1. Khá»Ÿi Ä‘á»™ng Airflow Webserver (Terminal 1)

```bash
# Activate venv
cd ~/airflow
source venv/bin/activate

# Khá»Ÿi Ä‘á»™ng webserver
airflow webserver --port 8080
```

**Hoáº·c cháº¡y background:**
```bash
nohup airflow webserver --port 8080 > ~/airflow/logs/webserver.log 2>&1 &
```

### 6.2. Khá»Ÿi Ä‘á»™ng Airflow Scheduler (Terminal 2)

```bash
# Activate venv
cd ~/airflow
source venv/bin/activate

# Khá»Ÿi Ä‘á»™ng scheduler
airflow scheduler
```

**Hoáº·c cháº¡y background:**
```bash
nohup airflow scheduler > ~/airflow/logs/scheduler.log 2>&1 &
```

### 6.3. Hoáº·c dÃ¹ng Airflow Standalone (Táº¥t cáº£ trong 1)

```bash
# Activate venv
cd ~/airflow
source venv/bin/activate

# Cháº¡y standalone (webserver + scheduler)
airflow standalone
```

**LÆ°u Ã½:** Standalone tá»± Ä‘á»™ng táº¡o user admin vá»›i password Ä‘Æ°á»£c in ra terminal.

---

## ğŸŒ BÆ°á»›c 7: Truy cáº­p Airflow UI

1. Má»Ÿ trÃ¬nh duyá»‡t
2. Truy cáº­p: **http://localhost:8080**
3. ÄÄƒng nháº­p:
   - Username: `admin`
   - Password: `admin` (hoáº·c password báº¡n Ä‘Ã£ set)

---

## âœ… BÆ°á»›c 8: Kiá»ƒm tra vÃ  Enable DAGs

### 8.1. Kiá»ƒm tra DAGs trong UI

1. VÃ o tab **DAGs**
2. TÃ¬m DAGs:
   - `ml_streaming_pipeline`
   - `ml_streaming_visualization`

### 8.2. Enable DAGs

1. TÃ¬m toggle switch bÃªn trÃ¡i tÃªn DAG
2. Click Ä‘á»ƒ chuyá»ƒn tá»« **OFF** â†’ **ON** (mÃ u xanh)

### 8.3. Kiá»ƒm tra DAG khÃ´ng cÃ³ lá»—i

- DAG khÃ´ng cÃ³ dáº¥u **X Ä‘á»** = OK
- Náº¿u cÃ³ X Ä‘á», click vÃ o Ä‘á»ƒ xem lá»—i

---

## ğŸ”§ BÆ°á»›c 9: Cáº¥u hÃ¬nh Spark Connection (Náº¿u cáº§n)

### 9.1. VÃ o Connections

1. Airflow UI â†’ **Admin** â†’ **Connections**
2. TÃ¬m hoáº·c táº¡o connection vá»›i ID: `spark_default`

### 9.2. Cáº¥u hÃ¬nh Connection

**Náº¿u dÃ¹ng Spark Standalone:**
- **Connection Type**: `Spark`
- **Host**: `192.168.1.19` (IP cá»§a Spark Master)
- **Port**: `7077`
- **Extra**: `{"queue": "default"}`

**Náº¿u dÃ¹ng Local Mode:**
- **Connection Type**: `Spark`
- **Host**: `local[*]`
- **Port**: (Ä‘á»ƒ trá»‘ng)
- **Extra**: `{"queue": "default"}`

**LÆ°u Ã½:** DAG hiá»‡n táº¡i khÃ´ng dÃ¹ng connection (Ä‘Ã£ set `conn_id=None`), nhÆ°ng cÃ³ thá»ƒ cáº§n cho cÃ¡c DAG khÃ¡c.

---

## ğŸ›‘ BÆ°á»›c 10: Dá»«ng Airflow

### 10.1. Náº¿u cháº¡y foreground (Ctrl+C)

```bash
# Trong terminal cháº¡y webserver/scheduler
Ctrl+C
```

### 10.2. Náº¿u cháº¡y background

```bash
# TÃ¬m process
ps aux | grep airflow

# Kill process
pkill -f "airflow webserver"
pkill -f "airflow scheduler"
```

---

## ğŸ“ Checklist hoÃ n chá»‰nh

- [ ] Python 3.9+ Ä‘Ã£ Ä‘Æ°á»£c cÃ i
- [ ] Virtual environment Ä‘Ã£ Ä‘Æ°á»£c táº¡o vÃ  activate
- [ ] Airflow 2.7.0 Ä‘Ã£ Ä‘Æ°á»£c cÃ i
- [ ] Spark provider Ä‘Ã£ Ä‘Æ°á»£c cÃ i
- [ ] Python dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i (pyspark, pandas, kafka-python, matplotlib)
- [ ] Airflow database Ä‘Ã£ Ä‘Æ°á»£c init (`airflow db init`)
- [ ] User admin Ä‘Ã£ Ä‘Æ°á»£c táº¡o
- [ ] DAGs Ä‘Ã£ Ä‘Æ°á»£c symlink vÃ o `~/airflow/dags/`
- [ ] Airflow webserver Ä‘ang cháº¡y (port 8080)
- [ ] Airflow scheduler Ä‘ang cháº¡y
- [ ] CÃ³ thá»ƒ truy cáº­p Airflow UI (http://localhost:8080)
- [ ] DAGs Ä‘Ã£ Ä‘Æ°á»£c enable trong UI
- [ ] Spark connection Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh (náº¿u cáº§n)

---

## ğŸ› Troubleshooting

### Lá»—i: "airflow: command not found"

**NguyÃªn nhÃ¢n:** ChÆ°a activate virtual environment hoáº·c Airflow chÆ°a Ä‘Æ°á»£c cÃ i

**Giáº£i phÃ¡p:**
```bash
source ~/airflow/venv/bin/activate
which airflow  # Kiá»ƒm tra Ä‘Æ°á»ng dáº«n
```

### Lá»—i: "Port 8080 already in use"

**NguyÃªn nhÃ¢n:** Port 8080 Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng

**Giáº£i phÃ¡p:**
```bash
# TÃ¬m process Ä‘ang dÃ¹ng port 8080
lsof -i :8080

# Kill process hoáº·c dÃ¹ng port khÃ¡c
airflow webserver --port 8081
```

### Lá»—i: "DAG not found"

**NguyÃªn nhÃ¢n:** DAG file chÆ°a Ä‘Æ°á»£c symlink hoáº·c cÃ³ lá»—i syntax

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra symlink
ls -la ~/airflow/dags/

# Kiá»ƒm tra syntax
source ~/airflow/venv/bin/activate
python3 -c "import sys; sys.path.insert(0, '~/airflow/dags'); from ml_pipeline_dag import dag; print('OK')"
```

### Lá»—i: "ModuleNotFoundError"

**NguyÃªn nhÃ¢n:** Thiáº¿u Python packages trong Airflow venv

**Giáº£i phÃ¡p:**
```bash
source ~/airflow/venv/bin/activate
pip install <package_name>
```

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Airflow Official Documentation](https://airflow.apache.org/docs/)
- [Airflow Installation Guide](https://airflow.apache.org/docs/apache-airflow/stable/start.html)
- [Airflow Spark Provider](https://airflow.apache.org/docs/apache-airflow-providers-apache-spark/stable/index.html)

---

## ğŸ¯ Quick Start Commands (Airflow 3.1.3)

```bash
# 1. Táº¡o vÃ  activate venv
mkdir -p ~/airflow && cd ~/airflow
python3 -m venv venv
source venv/bin/activate

# 2. CÃ i Ä‘áº·t Airflow 3.1.3 vÃ  dependencies
pip install apache-airflow==3.1.3
pip install apache-airflow-providers-apache-spark
pip install pyspark==4.0.0 pandas scikit-learn kafka-python matplotlib numpy

# 3. Khá»Ÿi táº¡o database
export AIRFLOW_HOME=~/airflow
airflow db init

# 4. Táº¡o user admin
airflow users create --username admin --firstname Admin --lastname User \
    --role Admin --email admin@example.com --password admin

# 5. Symlink DAGs
ln -sf /home/haminhchien/Documents/bigdata/final_project/dags/ml_pipeline_dag.py \
    ~/airflow/dags/ml_pipeline_dag.py

# 6. Khá»Ÿi Ä‘á»™ng Airflow
airflow standalone
# Hoáº·c riÃªng biá»‡t:
# Terminal 1: airflow webserver --port 8080
# Terminal 2: airflow scheduler

# 7. Truy cáº­p UI
# Má»Ÿ browser: http://localhost:8080
# Login: admin/admin
```

## âš ï¸ LÆ°u Ã½ Ä‘áº·c biá»‡t cho Airflow 3.1.3

### Thay Ä‘á»•i trong Airflow 3.x:
1. **Import paths**: Má»™t sá»‘ operators Ä‘Ã£ Ä‘Æ°á»£c di chuyá»ƒn
   - `airflow.operators.bash` â†’ `airflow.providers.standard.operators.bash`
   - `airflow.operators.python` â†’ `airflow.providers.standard.operators.python`

2. **DAG structure**: Vá» cÆ¡ báº£n giá»‘ng nhau nhÆ°ng cÃ³ thá»ƒ cÃ³ má»™t sá»‘ thay Ä‘á»•i nhá»

3. **Database**: CÃ³ thá»ƒ cáº§n migrate náº¿u upgrade tá»« 2.x

### Kiá»ƒm tra version:
```bash
source ~/airflow/venv/bin/activate
airflow version
# Káº¿t quáº£ mong Ä‘á»£i: 3.1.3
```

---

ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰

