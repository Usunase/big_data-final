# CÃ¡c bÆ°á»›c tiáº¿p theo sau khi táº¡o Spark Connection

## âš ï¸ Quan trá»ng: Kiá»ƒm tra cáº¥u hÃ¬nh Connection

Báº¡n Ä‘Ã£ táº¡o connection vá»›i:
- Host: `master:7077` (Spark standalone cluster)
- Port: `7077`

NhÆ°ng DAG cá»§a báº¡n Ä‘ang cáº¥u hÃ¬nh Ä‘á»ƒ cháº¡y á»Ÿ **local mode** (`local[*]`).

### CÃ³ 2 lá»±a chá»n:

---

## Lá»±a chá»n 1: DÃ¹ng Local Mode (ÄÆ¡n giáº£n hÆ¡n - Khuyáº¿n nghá»‹)

Náº¿u báº¡n cháº¡y Spark trÃªn cÃ¹ng mÃ¡y (local), cáº§n **sá»­a connection**:

1. Click vÃ o **icon Edit** (bÃºt chÃ¬) cá»§a connection `spark_default`
2. Sá»­a cÃ¡c trÆ°á»ng:
   - **Host**: `local[*]` (thay vÃ¬ `master:7077`)
   - **Port**: Äá»ƒ **trá»‘ng** (xÃ³a `7077`)
3. Click **Sauvegarder** (Save)

âœ… **Æ¯u Ä‘iá»ƒm**: KhÃ´ng cáº§n Spark cluster, cháº¡y trá»±c tiáº¿p trÃªn mÃ¡y

---

## Lá»±a chá»n 2: DÃ¹ng Spark Standalone Cluster

Náº¿u báº¡n cÃ³ Spark standalone cluster Ä‘ang cháº¡y:

1. **Giá»¯ nguyÃªn connection** (Host: `master:7077`, Port: `7077`)
2. **Sá»­a DAG** Ä‘á»ƒ khÃ´ng override `spark.master`:
   - Má»Ÿ `dags/ml_pipeline_dag.py`
   - XÃ³a hoáº·c comment dÃ²ng `'spark.master': 'local[*]'` trong `conf`

âœ… **Æ¯u Ä‘iá»ƒm**: Táº­n dá»¥ng cluster, xá»­ lÃ½ nhanh hÆ¡n

---

## ğŸ“‹ CÃ¡c bÆ°á»›c tiáº¿p theo Ä‘á»ƒ cháº¡y DAG

### BÆ°á»›c 1: Äáº£m báº£o cÃ¡c services Ä‘ang cháº¡y

```bash
# Kiá»ƒm tra Kafka
docker ps | grep kafka

# Náº¿u chÆ°a cháº¡y, khá»Ÿi Ä‘á»™ng:
cd docker
docker-compose up -d
```

### BÆ°á»›c 2: Kiá»ƒm tra DAG trong Airflow

1. VÃ o Airflow UI: http://localhost:8080
2. Click vÃ o tab **DAGs**
3. TÃ¬m DAG: `ml_streaming_pipeline`
4. Kiá»ƒm tra:
   - âœ… DAG cÃ³ mÃ u xanh (enabled)
   - âœ… KhÃ´ng cÃ³ lá»—i (mÃ u Ä‘á»)

### BÆ°á»›c 3: Trigger DAG

1. Click vÃ o DAG `ml_streaming_pipeline`
2. Click nÃºt **â–¶ï¸ Play** (Trigger DAG) á»Ÿ gÃ³c trÃªn bÃªn pháº£i
3. Chá»n **Trigger DAG w/ config** (hoáº·c chá»‰ Trigger)
4. Click **Trigger**

### BÆ°á»›c 4: Theo dÃµi tiáº¿n trÃ¬nh

1. Click vÃ o DAG Ä‘á»ƒ xem **Graph View**
2. CÃ¡c task sáº½ chuyá»ƒn tá»« mÃ u xÃ¡m â†’ vÃ ng (running) â†’ xanh (success)
3. Click vÃ o tá»«ng task Ä‘á»ƒ xem logs náº¿u cÃ³ lá»—i

### BÆ°á»›c 5: Cháº¡y Visualization (tÃ¹y chá»n)

Sau khi DAG cháº¡y xong, Ä‘á»ƒ xem káº¿t quáº£ trá»±c quan:

1. TÃ¬m DAG: `ml_streaming_visualization`
2. Trigger DAG nÃ y
3. Hoáº·c cháº¡y thá»§ cÃ´ng:
   ```bash
   python visualization/kafka_consumer.py
   ```

---

## ğŸ” Kiá»ƒm tra káº¿t quáº£

### Xem logs cá»§a tá»«ng task:

1. Click vÃ o task trong Graph View
2. Click **Log** Ä‘á»ƒ xem chi tiáº¿t

### Kiá»ƒm tra mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c táº¡o:

```bash
ls -la models/house_price_model/
```

### Kiá»ƒm tra Kafka topics:

```bash
# VÃ o container Kafka
docker exec -it kafka bash

# List topics
kafka-topics --bootstrap-server localhost:9092 --list

# Xem messages trong topic
kafka-console-consumer --bootstrap-server localhost:9092 \
    --topic house-prices-output --from-beginning
```

---

## ğŸ› Troubleshooting

### Lá»—i: "Connection spark_default not found"

- Kiá»ƒm tra Connection ID pháº£i Ä‘Ãºng: `spark_default`
- Refresh trang Airflow

### Lá»—i: "Cannot connect to Spark master"

**Náº¿u dÃ¹ng local mode:**
- Sá»­a connection: Host = `local[*]`, Port = trá»‘ng
- Äáº£m báº£o Spark Ä‘Ã£ Ä‘Æ°á»£c cÃ i vÃ  `SPARK_HOME` Ä‘Æ°á»£c set

**Náº¿u dÃ¹ng standalone:**
- Kiá»ƒm tra Spark cluster Ä‘ang cháº¡y: `jps | grep Master`
- Kiá»ƒm tra cÃ³ thá»ƒ káº¿t ná»‘i: `telnet master 7077`

### Lá»—i: "Model not found"

- Task `train_model` pháº£i cháº¡y thÃ nh cÃ´ng trÆ°á»›c
- Kiá»ƒm tra file: `models/house_price_model/metadata/part-00000`

### Lá»—i: "Kafka connection refused"

```bash
# Kiá»ƒm tra Kafka
docker ps | grep kafka
docker logs kafka

# Restart náº¿u cáº§n
cd docker
docker-compose restart
```

---

## âœ… Checklist trÆ°á»›c khi cháº¡y

- [ ] Spark connection Ä‘Ã£ Ä‘Æ°á»£c táº¡o (`spark_default`)
- [ ] Kafka Ä‘ang cháº¡y (`docker ps | grep kafka`)
- [ ] DAG `ml_streaming_pipeline` Ä‘Ã£ Ä‘Æ°á»£c enable (mÃ u xanh)
- [ ] DAG khÃ´ng cÃ³ lá»—i syntax (khÃ´ng cÃ³ dáº¥u X Ä‘á»)
- [ ] ÄÃ£ cÃ i Ä‘áº·t dependencies: `pip install -r requirements.txt`
- [ ] Spark 4.0.0 Ä‘Ã£ Ä‘Æ°á»£c cÃ i vÃ  `SPARK_HOME` Ä‘Æ°á»£c set

---

## ğŸ¯ Thá»© tá»± thá»±c thi DAG

DAG sáº½ cháº¡y theo thá»© tá»±:

1. `start_kafka` - Khá»Ÿi Ä‘á»™ng Kafka
2. `check_kafka_ready` - Kiá»ƒm tra Kafka
3. `prepare_data` - Chuáº©n bá»‹ dá»¯ liá»‡u
4. `train_model` - Huáº¥n luyá»‡n mÃ´ hÃ¬nh
5. `start_streaming_job` - Khá»Ÿi Ä‘á»™ng Spark Streaming
6. `send_streaming_data` - Gá»­i dá»¯ liá»‡u vÃ o Kafka
7. `wait_for_streaming` - Äá»£i xá»­ lÃ½
8. `cleanup` - Dá»n dáº¹p

Tá»•ng thá»i gian: ~10-15 phÃºt (tÃ¹y vÃ o sá»‘ lÆ°á»£ng dá»¯ liá»‡u)

